---
output:
  reprex::reprex_document:
    venue: "gh"
    advertise: FALSE
    session_info: TRUE
    style: TRUE
    comment: "#;-)"
    tidyverse_quiet: FALSE
    std_out_err: TRUE
knit: reprex::reprex_render
---
## Data Cleaning
We decided to remove these columns: CASE_TYPE, FOLDER_TYPE, WORK, PERMIT_NUMBER, REFERENCEFILE, FOLDERRSN, LINK, APPLICANT_FIRST_NAME, APPLICANT_LAST_NAME, END_HOURS_MOV_VEH_MON_SAT, END_HOURS_MOV_VEH_SUN, PROPERTYRSN, START_HOURS_MOV_VEH_MON_SAT, START_HOURS_MOV_VEH_SUN, PROPX, PROPY, LOCATION, UPDATE_DATE, FOLDER_DESCRIPTION
```{r}
# install.packages("dplyr")  # this was for Nneoma, since it wasn't working for you
library(dplyr)

df <- read.csv("sound_ordinance_data.csv", na.strings = c("", "NA")) # ensured that blank strings are counting as NA

columns_to_remove <- c("CASE_TYPE", "FOLDER_TYPE", "WORK", "PERMIT_NUMBER", "REFERENCEFILE", "FOLDERRSN", "LINK", 
  "APPLICANT_FIRST_NAME", "APPLICANT_LAST_NAME","END_HOURS_MOV_VEH_MON_SAT", "END_HOURS_MOV_VEH_SUN", 
  "PROPERTYRSN", "START_HOURS_MOV_VEH_MON_SAT", "START_HOURS_MOV_VEH_SUN", "PROPX", "PROPY", "LOCATION", "UPDATE_DATE", "FOLDER_DESCRIPTION",
  "FOLDER_NAME", "EVENT_YEAR", "APPLICANT_ORGANIZATION", "START_DATE_3", "START_DATE_4")
df <- df %>% select(-all_of(columns_to_remove))


df <- df %>% rename(EVENT_YEAR = CALENDAR_YEAR_FOLDER_CREATED)
df <- df %>% filter(!is.na(COUNCIL_DISTRICT))
df <- df %>% filter(!is.na(CALENDAR_YEAR_FOLDER_CREATED))
df <- df %>% filter(!is.na(EVENT_YEAR))
df <- df %>% filter(!is.na(EXISTING_ZONING))
df <- df %>% filter(!is.na(ISSUED_BY))
df <- df %>% filter(!is.na(START_HOURS_CONC_POUR_MON_SAT))

# unique_counts <- sapply(df, function(col), length(unique(col)))
# print(unique_counts)

colSums(is.na(df))
df$START_DATE_2 <- !(df$START_DATE_2 == "" | is.na(df$START_DATE_2)) # flipped it to make majority of set false instead of true


df <- df %>% rename(MULTIPLE_START_DATES = START_DATE_2)

unique_values <- unique(df$EVENT_MONTH)
# unique_values <- unique(df$OMV_TUE_START_TIME)
unique_values

# table(df$OMV_TUE_END_TIME)
# table(df$ISSUED_BY)


```

The convert_time method will be used to change hours into numbers
```{r}
# Nneoma's convert time method
# Function to convert time strings to numbers - if values dont have am or pm, it will return -100
convert_time <- function(time) {
  if (is.na(time) || time == 'NA') { #returns null values
    return(NA)
  }
  time <- trimws(tolower(time))  # Make everything lowercase and remove extra spaces
  if (time == 'midnight') {
    return(0)
  }
  if (time == 'noon') {
    return(12)
  }
  
  time <- gsub("[[:space:].]", "", tolower(time)) # Normalize time by removing spaces and periods

  am_or_pm <- substr(time, nchar(time) - 1, nchar(time)) # Check if the string ends with "am" or "pm"
  time <- gsub(am_or_pm, "", time) #removes the end
   # Handle times like "6:30", "9:45", etc., by extracting only the hour
  if (grepl(":", time)) {
    time <- sub(":.*", "", time)  # Remove minutes, keep the hour part
  }

  if (am_or_pm == "am") {
    #time <- sub("am", "", time)  # Remove 'am'
    #time <- trimws(time)  # Trim extra spaces
    if (time == "" || time == "12" || time == "midnight") {
      return(0)  # If it's "12am", return 0
    }
    return(as.numeric(time))
  } else if (am_or_pm == "pm") {
    #hour <- as.numeric(time)
    if (time == "12" || time == "noon") {
      return(12)  # If it's "12pm", return 12
    }
    return(as.numeric(time) + 12)  # Add 12 for PM times
  } else {
    return(-100)  # If time format is unrecognized, return an error
  }
  
}


```

# Greg
```{r, echo=FALSE}
# GREG 
library(stringr)

# Function to convert time strings to military time
normalize_time <- function(time_str) {
  time_str <- str_trim(tolower(time_str)) # Convert to lowercase for consistency
  
  # Handle special cases
  if (time_str %in% c("midnight", "12am", "12:00am")) {
    return("00:00")
  }
  if (time_str %in% c("12pm", "12:00pm")) {
    return("12:00")
  }
  if (time_str %in% c("1:00m")) {
    return("01:00")
  }
  
  # Extract hours, minutes, and AM/PM if present
  matches <- str_match(time_str, "^(\\d{1,2})(?::(\\d{2}))?\\s*(a\\.m\\.|p\\.m\\.|am|pm)?$")
  if (!is.na(matches[1])) {
    hour <- as.numeric(matches[2])
    minute <- ifelse(is.na(matches[3]), "00", matches[3])
    period <- matches[4]
    
    # Convert to 24-hour format
    if (!is.na(period)) {
      if (period %in% c("pm", "p.m.") && hour != 12) {
        hour <- hour + 12
      }
      if (period %in% c("am", "a.m.") && hour == 12) {
        hour <- 0
      }
    }
    return(sprintf("%02d:%02d", hour, as.numeric(minute)))
  }
  # Return NA for unrecognized formats
  return("0:00")
}

# Apply normalization to the column
nrow(df$START_HOURS_CONC_POUR_MON_SAT)
df$START_HOURS_CONC_POUR_MON_SAT <- df$START_HOURS_CONC_POUR_MON_SAT[!is.na(df$START_HOURS_CONC_POUR_MON_SAT) & df$START_HOURS_CONC_POUR_MON_SAT != "NA"]
nrow(df$START_HOURS_CONC_POUR_MON_SAT)


df$START_HOURS_CONC_POUR_MON_SAT <- sapply(df$START_HOURS_CONC_POUR_MON_SAT, normalize_time)
print(unique(df$START_HOURS_CONC_POUR_MON_SAT))

```


```{r}
# ESHI 

```


```{r}
# DANIEL 

```


Nneoma is cleaning the values START_HOURS_NOT_NEAR_HOME, END_HOURS_NOT_NEAR_HOME, STATUS, EXPIRATION_DATE	(YYYY-MM-DD),
IN_DATE (YYYY-MM-DD), ISSUE_DATE, ISSUED_BY (YYYY-MM-DD), START_DATE, and has_multiple_start_dates
```{r}
# NNEOMA 
#nrow(df)
#************** START_DATE has 1,458 missing values -- if event month is blank, then start_date will be blank
#df$START_DATE
unique(df$START_DATE)
df %>% filter(is.na(df$START_DATE)) %>% select(START_DATE, STATUS) #checking cols of null start_date

#ISSUE DATE -- everything is clean and no missing values
unique(df$ISSUE_DATE)
df %>% select(ISSUE_DATE)  #%>%  filter(is.na(ISSUE_DATE))#checking cols of null start_date

#IN DATE -- everything is clean and no missing values
unique(df$IN_DATE)
df %>% select(IN_DATE)#filter(is.na(IN_DATE))  %>%   #checking cols of null start_date
head(df$IN_DATE, 1000)

# *********EXPIRATION_DATE -- if start_date is NA, then ex_date is NA

unique(df$EXPIRATION_DATE)
df %>% filter(is.na(EXPIRATION_DATE) & STATUS=='Expired') %>% select(EXPIRATION_DATE, START_DATE, STATUS) #  %>% summarize(n())  #checking cols of null start_date
head(df$EXPIRATION_DATE, 1000)

# ISSUEd_BY -- everything is clean and no missing values
table(df$ISSUED_BY)
unique(df$ISSUED_BY)
df %>% filter(is.na(ISSUED_BY))# %>% select(EXPIRATION_DATE, START_DATE, STATUS) #  %>% summarize(n())  #checking cols of null start_date
head(df, 1)

# MULTIPLE_START_DATES -- i am making a subset of rows that have multiple start dates
df_multiple_starts <- df %>% filter(MULTIPLE_START_DATES == TRUE)
df_multiple_starts 

# *****START_HOURS_NOT_NEAR_HOME --  converted string times into numeric numbers
# replaced that pending review with a NA value
df$START_HOURS_NOT_NEAR_HOME <- ifelse(df$START_HOURS_NOT_NEAR_HOME == 'Pending Review', NA, df$START_HOURS_NOT_NEAR_HOME)
df$START_HOURS_NOT_NEAR_HOME <- gsub("an", "am", df$START_HOURS_NOT_NEAR_HOME) # fixed a typo
# changed 12:00 to 12:00PM
df$START_HOURS_NOT_NEAR_HOME <- ifelse(df$START_HOURS_NOT_NEAR_HOME == '12:00', "12:00 PM", df$START_HOURS_NOT_NEAR_HOME)

df$START_HOURS_NOT_NEAR_HOME <- sapply(df$START_HOURS_NOT_NEAR_HOME, convert_time) # converting column to numbers
#df$START_HOURS_NOT_NEAR_HOME <- ifelse(test$START_HOURS_NOT_NEAR_HOME == -100, NA, test$START_HOURS_NOT_NEAR_HOME) #making -100 into NA
table(df$START_HOURS_NOT_NEAR_HOME)

df %>% filter(!is.na(START_HOURS_NOT_NEAR_HOME)) %>% select(START_HOURS_NOT_NEAR_HOME)

head(df)
```


```{r}
# MAADHAV 

```