---
output:
  reprex::reprex_document:
    venue: "gh"
    advertise: FALSE
    session_info: TRUE
    style: TRUE
    comment: "#;-)"
    tidyverse_quiet: FALSE
    std_out_err: TRUE
knit: reprex::reprex_render
---
## Data Cleaning
We decided to remove these columns: CASE_TYPE, FOLDER_TYPE, WORK, PERMIT_NUMBER, REFERENCEFILE, FOLDERRSN, LINK, APPLICANT_FIRST_NAME, APPLICANT_LAST_NAME, END_HOURS_MOV_VEH_MON_SAT, END_HOURS_MOV_VEH_SUN, PROPERTYRSN, START_HOURS_MOV_VEH_MON_SAT, START_HOURS_MOV_VEH_SUN, PROPX, PROPY, LOCATION, UPDATE_DATE, FOLDER_DESCRIPTION
```{r}
# install.packages("dplyr")  # this was for Nneoma, since it wasn't working for you
library(dplyr)

df <- read.csv("sound_ordinance_data.csv", na.strings = c("", "NA")) # ensured that blank strings are counting as NA

columns_to_remove <- c("CASE_TYPE", "FOLDER_TYPE", "WORK", "PERMIT_NUMBER", "REFERENCEFILE", "FOLDERRSN", "LINK", 
  "APPLICANT_FIRST_NAME", "APPLICANT_LAST_NAME","END_HOURS_MOV_VEH_MON_SAT", "END_HOURS_MOV_VEH_SUN", 
  "PROPERTYRSN", "START_HOURS_MOV_VEH_MON_SAT", "START_HOURS_MOV_VEH_SUN", "PROPX", "PROPY", "LOCATION", "UPDATE_DATE", "FOLDER_DESCRIPTION",
  "FOLDER_NAME", "EVENT_YEAR", "APPLICANT_ORGANIZATION", "START_DATE_3", "START_DATE_4")
df <- df %>% select(-all_of(columns_to_remove))


df <- df %>% rename(EVENT_YEAR = CALENDAR_YEAR_FOLDER_CREATED)
df <- df %>% filter(!is.na(COUNCIL_DISTRICT))
df <- df %>% filter(!is.na(CALENDAR_YEAR_FOLDER_CREATED))
df <- df %>% filter(!is.na(EVENT_YEAR))
df <- df %>% filter(!is.na(EXISTING_ZONING))
df <- df %>% filter(!is.na(ISSUED_BY))

# unique_counts <- sapply(df, function(col), length(unique(col)))
# print(unique_counts)

colSums(is.na(df))
df$START_DATE_2 <- !(df$START_DATE_2 == "" | is.na(df$START_DATE_2)) # flipped it to make majority of set false instead of true


df <- df %>% rename(MULTIPLE_START_DATES = START_DATE_2)

unique_values <- unique(df$EVENT_MONTH)
# unique_values <- unique(df$OMV_TUE_START_TIME)
unique_values

# table(df$OMV_TUE_END_TIME)
# table(df$ISSUED_BY)


```

The convert_time method will be used to change hours into numbers
```{r}
# Nneoma's convert time method
# Function to convert time strings to numbers
convert_time <- function(time) {
  if (is.na(time) || time == 'NA') { #returns null values
    return(NA)
  }
  time <- trimws(tolower(time))  # Make everything lowercase and remove extra spaces
  if (time == 'midnight') {
    return(0)
  }
  if (time == 'noon') {
    return(12)
  }
  
  time <- gsub("[[:space:].]", "", tolower(time)) # Normalize time by removing spaces and periods

  am_or_pm <- substr(time, nchar(time) - 1, nchar(time)) # Check if the string ends with "am" or "pm"
  time <- gsub(am_or_pm, "", time) #removes the end
   # Handle times like "6:30", "9:45", etc., by extracting only the hour
  if (grepl(":", time)) {
    time <- sub(":.*", "", time)  # Remove minutes, keep the hour part
  }

  if (am_or_pm == "am") {
    #time <- sub("am", "", time)  # Remove 'am'
    #time <- trimws(time)  # Trim extra spaces
    if (time == "" || time == "12" || time == "midnight") {
      return(0)  # If it's "12am", return 0
    }
    return(as.numeric(time))
  } else if (am_or_pm == "pm") {
    #hour <- as.numeric(time)
    if (time == "12" || time == "noon") {
      return(12)  # If it's "12pm", return 12
    }
    return(as.numeric(time) + 12)  # Add 12 for PM times
  } else {
    return(NA)  # If time format is unrecognized, return the original string
  }
  
}


```


```{r}
# GREG 

```


```{r}
# ESHI 

```


```{r}
# DANIEL 

```


Nneoma is cleaning the values START_HOURS_NOT_NEAR_HOME, END_HOURS_NOT_NEAR_HOME, STATUS, EXPIRATION_DATE	(YYYY-MM-DD),
IN_DATE (YYYY-MM-DD), ISSUE_DATE, ISSUED_BY (YYYY-MM-DD), START_DATE, and has_multiple_start_dates
```{r}
# NNEOMA 
#nrow(df)
#************** START_DATE has 1,458 missing values -- if event month is blank, then start_date will be blank
#df$START_DATE
unique(df$START_DATE)
df %>% filter(is.na(df$START_DATE)) %>% select(START_DATE, STATUS) #checking cols of null start_date

#ISSUE DATE -- everything is clean and no missing values
unique(df$ISSUE_DATE)
df %>% select(ISSUE_DATE)  #%>%  filter(is.na(ISSUE_DATE))#checking cols of null start_date

#IN DATE -- everything is clean and no missing values
unique(df$IN_DATE)
df %>% select(IN_DATE)#filter(is.na(IN_DATE))  %>%   #checking cols of null start_date
head(df$IN_DATE, 1000)

# *********EXPIRATION_DATE -- if start_date is NA, then ex_date is NA

unique(df$EXPIRATION_DATE)
df %>% filter(is.na(EXPIRATION_DATE) & STATUS=='Expired') %>% select(EXPIRATION_DATE, START_DATE, STATUS) #  %>% summarize(n())  #checking cols of null start_date
head(df$EXPIRATION_DATE, 1000)

# ISSUEd_BY -- everything is clean and no missing values
table(df$ISSUED_BY)
unique(df$ISSUED_BY)
df %>% filter(is.na(ISSUED_BY))# %>% select(EXPIRATION_DATE, START_DATE, STATUS) #  %>% summarize(n())  #checking cols of null start_date
head(df, 1)

# MULTIPLE_START_DATES -- i am making a subset of rows that have multiple start dates
df_multiple_starts <- df %>% filter(MULTIPLE_START_DATES == TRUE)
df_multiple_starts 

# ************START_HOURS_NOT_NEAR_HOME
# replaced that pending review with a NA value
df$START_HOURS_NOT_NEAR_HOME <- ifelse(df$START_HOURS_NOT_NEAR_HOME == 'Pending Review', NA, df$START_HOURS_NOT_NEAR_HOME)
df$START_HOURS_NOT_NEAR_HOME <- gsub("an", "am", df$START_HOURS_NOT_NEAR_HOME)
table(df$START_HOURS_NOT_NEAR_HOME)
convert_time('8:00a')

vec <- sapply(df$START_HOURS_NOT_NEAR_HOME, convert_time)

test$START_HOURS_NOT_NEAR_HOME <- vec
test$START_HOURS_NOT_NEAR_HOME

table(test$START_HOURS_NOT_NEAR_HOME)

df %>% filter(!is.na(START_HOURS_NOT_NEAR_HOME)) %>% select(START_HOURS_NOT_NEAR_HOME)

test %>% filter(!is.na(START_HOURS_NOT_NEAR_HOME)) %>% select(START_HOURS_NOT_NEAR_HOME)



head(df)
```


```{r}
# MAADHAV 

```